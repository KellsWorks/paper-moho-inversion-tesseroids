{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moho of South America\n",
    "\n",
    "This notebook applies the proposed gravity inversion method to estimate the Moho of South America. We'll use the same cross-validation methods presented in the [synthetic-crust1.ipynb](synthetic-crust1.ipynb) notebook to determined the optimal regularization parameter, density contrast, and reference height. The data used here was downloaded from the [ICGEM web service](http://icgem.gfz-potsdam.de/ICGEM/) and processes in the [process-sam-gravity-data.ipynb](process-sam-gravity-data.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports\n",
    "\n",
    "Load the necessary libraries to run the inversion and make graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the plots into the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the standard scientific Python stack to numerical analysis and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import datetime\n",
    "import zipfile\n",
    "import cPickle as pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import multiprocessing\n",
    "import seaborn  # Makes the default style of the plots nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computations generate a lot of run-time warnings. They aren't anything to be concerned about so disable them to avoid clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required modules from [Fatiando a Terra](http://www.fatiando.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fatiando.vis import mpl\n",
    "from fatiando.gravmag import tesseroid\n",
    "from fatiando import gridder, utils\n",
    "from fatiando.inversion import Smoothness2D\n",
    "import fatiando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Version of Fatiando a Terra used: {}\".format(fatiando.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our custom classes and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import fetch_assumpcao_moho_points\n",
    "from mohoinv import (MohoGravityInvSpherical, TesseroidRelief, make_mesh,\n",
    "                     split_data, score_test_set, score_seismic_constraints, \n",
    "                     score_all, fit_all, predict_seismic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of cores in this computer to run the some things in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpu = multiprocessing.cpu_count()\n",
    "print(\"Number of cores: {}\".format(ncpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the gravity data\n",
    "\n",
    "Load the processed gravity anomaly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed-data-malawi.txt') as f:\n",
    "    for i in range(3):  # Skip the first 2 header lines\n",
    "        line = f.readline()\n",
    "    full_shape = [int(x) for x in line.split()[1:]]\n",
    "    full_lat, full_lon, full_height, full_grav = np.loadtxt(f, usecols=[0, 1, 2, -1], \n",
    "                                                            unpack=True)\n",
    "    full_data = [full_lat, full_lon, full_height, full_grav]\n",
    "print('Number of data points in lat and lon: {}'.format(full_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the full dataset. We'll use a portion of it for the inversion and the rest for [cross-validation](#Cross-validation). \n",
    "\n",
    "Make a plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_area = (full_lat.min(), full_lat.max(), full_lon.min(), full_lon.max())\n",
    "bm = Basemap(projection='cyl', \n",
    "             llcrnrlon=full_area[2], urcrnrlon=full_area[3], \n",
    "             llcrnrlat=full_area[0], urcrnrlat=full_area[1],\n",
    "             resolution='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bm(full_lon, full_lat)\n",
    "ranges = np.abs([full_grav.min(), full_grav.max()]).max()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Sediment-free Bouguer Anomaly')\n",
    "bm.contourf(x, y, full_grav, 60, tri=True, cmap='RdBu_r', vmin=-ranges, vmax=ranges)\n",
    "plt.colorbar(pad=0.01, aspect=50).set_label('mGal')\n",
    "bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 0, 1], linewidth=0.2)\n",
    "bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inversion will use only a portion of the data for inversion. The rest will be used for cross-validation to determine an optimal regularization parameter.\n",
    "\n",
    "We'll use the `split_data` function from [mohoinv.py](mohoinv.py) to separate the dataset into the two parts by taking every other 2 points for inversion and keeping the rest for cross-validation (testing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion_set, test_set, shape = split_data(full_data, full_shape, every_other=2)\n",
    "\n",
    "print(\"Number of inversion grid points: {} x {} = {}\".format(shape[0], shape[1], \n",
    "                                                             shape[0]*shape[1]))\n",
    "print(\"Number of test set points: {}\".format(test_set[0].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the inversion data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, height, data = inversion_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bm(lon, lat)\n",
    "ranges = np.abs([data.min(), data.max()]).max()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Sediment-free Bouguer Anomaly (inversion data)')\n",
    "bm.contourf(x, y, data, 60, tri=True, cmap='RdBu_r', vmin=-ranges, vmax=ranges)\n",
    "plt.colorbar(pad=0.01, aspect=50).set_label('mGal')\n",
    "bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 0, 1], linewidth=0.2)\n",
    "bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the seismic point constraints. This is used in cross-validation to find the reference level and the density contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = fetch_assumpcao_moho_points('../data/Moho_Map_SAm2013_data.tar.gz', \n",
    "                                          todepth=True, return_height=False)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longitude for the seismic points is in the range [-180, 180] but we need it in [0, 360] because the gravity data is  that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points[1] += 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the seismic points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bm(test_points[1], test_points[0])\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Moho depth point constraints')\n",
    "bm.scatter(x, y, c=-0.001*test_points[-1], s=20, cmap='Greens')\n",
    "plt.colorbar(pad=0.01, aspect=50).set_label('km')\n",
    "bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 0, 1], linewidth=0.2)\n",
    "bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "bm.drawcoastlines(color=\"#666666\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion setup\n",
    "\n",
    "Create the objects and configuration that we'll need to run the inversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate a `TesseroidRelief` mesh for the inversion, give it a reference level and a density contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = (lat.min(), lat.max(), lon.min(), lon.max())\n",
    "mesh = make_mesh(area, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need an initial estimate, the solver and its configuration, and a regularization object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misfit = MohoGravityInvSpherical(lat, lon, height, data, mesh)\n",
    "regul = Smoothness2D(mesh.shape)\n",
    "initial = -60e3*np.ones(mesh.size)  \n",
    "# The initial estimate doesn't really matter too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions\n",
    "\n",
    "We'll define some plotting functions here to avoid having all this code down with the results. You can safely skip (not read) this section because we only define the functions here. They are called after the inversion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(lat, lon, data, solution, bm):    \n",
    "    ranges = np.abs([data.max(), data.min()]).max()\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.title('Observed (color) and predicted (contour) data')    \n",
    "    levels = mpl.contourf(lon, lat, data, shape, 40, cmap='RdBu_r', basemap=bm, \n",
    "                          vmin=-ranges, vmax=ranges)\n",
    "    plt.colorbar(pad=0.01).set_label('mGal')\n",
    "    mpl.contour(lon, lat, solution[0].predicted(), shape, levels, \n",
    "                basemap=bm, color='#333333')\n",
    "    bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 0, 1], linewidth=0.2)\n",
    "    bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_residuals(solution):\n",
    "    residuals = solution[0].residuals()\n",
    "    \n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    plt.text(0.65, 0.8, \n",
    "             \"mean = {:.2f}\\nstd = {:.2f}\".format(residuals.mean(), residuals.std()), \n",
    "             transform=plt.gca().transAxes)\n",
    "    plt.hist(residuals, bins=20, normed=True, histtype='stepfilled')\n",
    "    plt.xlabel('Residuals (mGal)')\n",
    "    plt.ylabel('Normalized frequency')\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_estimate(solution, bm):\n",
    "    moho = solution.estimate_\n",
    "    x, y = bm(moho.lons, moho.lats)\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.title(\"Estimated Moho depth\")\n",
    "    bm.pcolormesh(x, y, -0.001*moho.relief.reshape(moho.shape), cmap='Greens')\n",
    "    plt.colorbar(pad=0.01).set_label('km')\n",
    "    bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 0, 1], linewidth=0.2)\n",
    "    bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_diff_seismic(solution, test_points, bm):\n",
    "    moho = solution.estimate_\n",
    "    x, y = bm(moho.lons, moho.lats)\n",
    "    diff = -0.001*(test_points[-1] - predict_seismic(moho, *test_points[:2]))\n",
    "    ranges = np.abs([diff.max(), diff.min()]).max()\n",
    "    lat, lon, depth = test_points\n",
    "    xp, yp = bm(lon, lat)\n",
    "   \n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "    bm.pcolormesh(x, y, -0.001*moho.relief.reshape(moho.shape), cmap='Greens')\n",
    "    plt.colorbar(pad=0.01, aspect=50).set_label('Estimated Moho depth (km)')\n",
    "    bm.scatter(xp, yp, c=diff, s=40, cmap='PuOr_r', \n",
    "                     vmin=-ranges, vmax=ranges, linewidths=0.1)\n",
    "    cb = plt.colorbar(pad=0.01, aspect=50)\n",
    "    cb.set_label('Difference between seismic and estimated (km)')\n",
    "    bm.drawmeridians(np.arange(-80, -30, 10), labels=[0, 0, 1, 0], linewidth=0.2)\n",
    "    bm.drawparallels(np.arange(-50, 30, 15), labels=[1, 0, 0, 0], linewidth=0.2)\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_diff_seismic_hist(solution, test_points):\n",
    "    moho = solution.estimate_\n",
    "    diff = -0.001*(test_points[-1] - predict_seismic(moho, *test_points[:2]))\n",
    "\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    plt.title('Difference (seismic points)')\n",
    "    plt.text(0.65, 0.8, \n",
    "             \"mean = {:.2f}\\nstd = {:.2f}\".format(diff.mean(), diff.std()), \n",
    "             transform=plt.gca().transAxes)\n",
    "    # Use the line above so the text coordinates are in axes coordinates (0 to 1)\n",
    "    # instead of data coordinates, which may vary between runs.\n",
    "    plt.hist(diff, bins=20, normed=True, histtype='stepfilled')\n",
    "    plt.xlabel('Differences (km)')\n",
    "    plt.ylabel('Normalized frequency')\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_cv_regul(regul_params, scores, best, log=True): \n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.title('Cross-validation (regularization parameter)')\n",
    "    plt.plot(regul_params, scores, marker='o')\n",
    "    plt.plot(regul_params[best], scores[best], 's', markersize=10, \n",
    "             color=seaborn.color_palette()[2], label='Minimum')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xscale('log')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    plt.xlabel('Regularization parameter')\n",
    "    plt.ylabel(u'Mean Square Error')\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_cv_ref_dens(densities, reference_levels, scores, best_dens, best_ref):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.title('Cross-validation (reference level and density)')\n",
    "    plt.contourf(-0.001*reference_levels, densities, scores, 30, cmap='BuPu_r')\n",
    "    plt.colorbar(pad=0.01).set_label('Mean Square Error')\n",
    "    plt.plot(-0.001*reference_levels[best_ref], densities[best_dens], 's', markersize=10, \n",
    "             color=seaborn.color_palette()[2], label='Minimum')\n",
    "    l = plt.legend(loc='upper left')\n",
    "    for txt in l.get_texts():\n",
    "        txt.set_color('#ffffff')\n",
    "    plt.xlabel('Reference level (km)')\n",
    "    plt.ylabel(u'Density contrast (kg/m³)')\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "def plot_convergence(solution, log=True):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.title('Convergence')\n",
    "    plt.plot(range(solution.stats_['iterations'] + 1), solution.stats_['objective'])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Goal function')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the inversion and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep the results in a Python dictionary (`dict`) along with all configuration and other metadata. We can then save this dict to a Pickle file and have inversion information saved with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the configuration for the solver. We'll use the Gauss-Newton formulation of the inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['config'] = dict(method='newton', initial=initial, tol=0.2, maxit=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the values of the regularization parameter, reference level, and density that we want to test during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['regul_params'] = np.logspace(-10, -2, 16)\n",
    "results['regul_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['reference_levels'] = np.arange(-40e3, -20e3 + 1, 2500)\n",
    "results['reference_levels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['densities'] = np.arange(200, 500 + 1, 50)\n",
    "results['densities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cross-validation to find the regularization parameter. We'll use one of the values for the reference and density contrast. The value of the regularization parameter that we estimate here will be used in the second cross-validation to find the density contrast and reference level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misfit.set_density(results['densities'][-1]).set_reference(results['reference_levels'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inversion for each value in `regul_params` (in parallel using all available cores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [(misfit + mu*regul).config(**results['config']) \n",
    "           for mu in results['regul_params']]\n",
    "\n",
    "%time solutions = fit_all(solvers, njobs=ncpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the estimated models in the results dict instead of the whole solvers to reduce the size of the pickle file. We can calculate the predicted data, etc, from the model only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['models_regul'] = [s.estimate_ for s in solutions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save these intermediate results in case something happens. This way we can resume computations from this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_results(results, intermediate=False):\n",
    "    now = datetime.datetime.utcnow().strftime('%d %B %Y %H:%M:%S UTC')\n",
    "    results['metadata'] = \"Generated by south-america-moho.ipynb on {date}\".format(\n",
    "        date=now)\n",
    "    if intermediate:\n",
    "        fname = 'results/south-america-moho.intermediate.pickle'\n",
    "    else:\n",
    "        fname = 'results/south-america-moho.pickle'\n",
    "    with open(fname, 'w') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_results(results, intermediate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the results against the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "results['scores_regul'] = score_all(results['models_regul'], test_set, points=False, \n",
    "                                    njobs=ncpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best solution is the one with the smallest cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regul = np.argmin(results['scores_regul'])\n",
    "results['best_regul'] = best_regul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this solution as the inversion solver for the next cross-validation (for the reference level and density)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['solution_regul'] = solutions[best_regul]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the intermediate results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_results(results, intermediate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the current solution. Plot the cross-validation scores, the inversion residuals, and the estimated solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_regul(results['regul_params'], results['scores_regul'], \n",
    "              best_regul, log=True)\n",
    "plt.grid(True, which='both', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(results['solution_regul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_estimate(results['solution_regul'], bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the second cross-validation to estimate the density-contrast and the reference level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ref_dens(solver, ref, dens):\n",
    "    \"\"\"\n",
    "    Configure the solver to use this reference level and density.\n",
    "    \"\"\"\n",
    "    res = solver.copy(deep=True)\n",
    "    # res is a multi-objective with the misfit function + regularization\n",
    "    # res[0] is the misfit (our inversion class)\n",
    "    # res[1] is the Smoothness2D instance\n",
    "    res[0].set_density(dens).set_reference(ref)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [set_ref_dens(results['solution_regul'], ref, dens) \n",
    "           for dens in results['densities'] \n",
    "           for ref in results['reference_levels']]\n",
    "\n",
    "%time solutions = fit_all(solvers, njobs=ncpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the only the estimated models in the results dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['models_refdens'] = [s.estimate_ for s in solutions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the estimates against the seismic constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the scores array because it should be a matrix \n",
    "# with density as the rows and reference level as the columns.\n",
    "# This will make it easier for us to find the best density and reference level below.\n",
    "cv_shape = (len(results['densities']), len(results['reference_levels']))\n",
    "results['scores_refdens'] = score_all(results['models_refdens'], \n",
    "                                      test_points, points=True).reshape(cv_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.nanargmin(results['scores_refdens'])\n",
    "# Find the index in reference_levels and densities corresponding to best\n",
    "results['best_dens'], results['best_ref'] = np.unravel_index(best, cv_shape)\n",
    "results['solution'] = solutions[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the estimated parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_ref = results['reference_levels'][results['best_ref']]\n",
    "estimated_dens = results['densities'][results['best_dens']]\n",
    "estimated_regul = results['regul_params'][results['best_regul']]\n",
    "print('Cross-validation results:')\n",
    "print(u'  reference level: {} km'.format(-0.001*estimated_ref))\n",
    "print(u'  density contrast: {} kg/m³'.format(estimated_dens))\n",
    "print(u'  regularization parameter: {}'.format(estimated_regul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final results into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_results(results, intermediate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the resulting pickle file will be large, we'll store it in a `zip` archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'south-america-moho'\n",
    "pickle_file = '{}.pickle'.format(fname)\n",
    "# Zip the pickle file\n",
    "zipargs = dict(mode='w', compression=zipfile.ZIP_DEFLATED)\n",
    "with zipfile.ZipFile('results/{}.zip'.format(fname), **zipargs) as f:\n",
    "    f.write('results/{}'.format(pickle_file), arcname=pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zip file is still too large for [Github](https://github.com/) (maximum allowed is 50 Mb). The way to store and commit the file is to split it into two with the `split` command-line program. We can assemble the two parts again using the `cat` program (see [paper-figures.ipynb](paper-figures.ipynb) for an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd results/\n",
    "split -b 30M --numeric-suffixes=1 south-america-moho.zip south-america-moho.zip.part\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also save the estimated Moho to a text file in xyz format for portability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.utcnow().strftime('%d %B %Y %H:%M:%S UTC')\n",
    "moho = results['solution'].estimate_\n",
    "header = \"\"\"# Moho of South America estimated by gravity data inversion\n",
    "# See the source code for the inversion at:\n",
    "#   https://github.com/pinga-lab/paper-moho-inversion-tesseroids\n",
    "# Generated by south-america-moho.ipynb on {date}\n",
    "# Model grid shape (nlat, nlon):\n",
    "#   {nlat} {nlon}\n",
    "# Latitude and longitude values correspond to the center of each\n",
    "# model cell.\n",
    "# Moho depth is provided in meters.\n",
    "# Columns:\n",
    "# lat lon Moho_depth\n",
    "\"\"\".format(date=now, nlat=moho.shape[0], nlon=moho.shape[1])\n",
    "with open('../model/south-american-moho.txt', 'w') as f:\n",
    "    f.write(header)\n",
    "    np.savetxt(f, np.c_[moho.clat.ravel(), moho.clon.ravel(), -moho.relief],\n",
    "               fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make quick plots of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_ref_dens(results['densities'], results['reference_levels'], \n",
    "                 results['scores_refdens'], results['best_dens'], \n",
    "                 results['best_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit(lat, lon, data, results['solution'], bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(results['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_estimate(results['solution'], bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff_seismic(results['solution'], test_points, bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff_seismic_hist(results['solution'], test_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
